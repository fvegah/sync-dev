---
phase: 03-progress-display
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - internal/models/progress.go
  - internal/sync/progress.go
autonomous: true

must_haves:
  truths:
    - "ProgressAggregator collects per-file progress data"
    - "Emissions are throttled to 10-20 Hz (50-100ms intervals)"
    - "Speed calculation uses exponential smoothing"
    - "ETA is calculated from smoothed speed"
  artifacts:
    - path: "internal/models/progress.go"
      provides: "AggregateProgress and FileProgress structs"
      contains: "AggregateProgress"
    - path: "internal/sync/progress.go"
      provides: "ProgressAggregator with throttling"
      contains: "ProgressAggregator"
  key_links:
    - from: "internal/sync/progress.go"
      to: "internal/models/progress.go"
      via: "import models"
      pattern: "models\\.AggregateProgress"
---

<objective>
Create the backend infrastructure for aggregated progress tracking with throttled emission and smoothed speed/ETA calculation.

Purpose: The current codebase emits progress callbacks on every 1MB chunk, causing UI freeze. This plan creates a ProgressAggregator that collects per-file data and emits throttled aggregate updates.

Output:
- `internal/models/progress.go` with AggregateProgress and FileProgress structs
- `internal/sync/progress.go` with ProgressAggregator implementation
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-progress-display/03-RESEARCH.md

# Key source files to understand current patterns
@internal/models/file.go
@internal/sync/transfer.go
@internal/sync/engine.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create progress models</name>
  <files>internal/models/progress.go</files>
  <action>
Create new file `internal/models/progress.go` with:

```go
package models

// AggregateProgress represents overall sync progress across all files
type AggregateProgress struct {
    Status           string         `json:"status"`           // "idle", "syncing", "complete"
    TotalFiles       int            `json:"totalFiles"`
    CompletedFiles   int            `json:"completedFiles"`
    TotalBytes       int64          `json:"totalBytes"`
    TransferredBytes int64          `json:"transferredBytes"`
    Percentage       float64        `json:"percentage"`
    BytesPerSecond   float64        `json:"bytesPerSecond"`   // smoothed speed
    ETA              int64          `json:"eta"`              // seconds remaining, -1 if unknown
    ActiveFiles      []FileProgress `json:"activeFiles"`      // max 10 files
}

// FileProgress represents progress for a single file
type FileProgress struct {
    Path        string  `json:"path"`
    Size        int64   `json:"size"`
    Transferred int64   `json:"transferred"`
    Percentage  float64 `json:"percentage"`
    Status      string  `json:"status"`  // "active", "pending", "complete"
}
```

Keep the existing TransferProgress struct in file.go for backward compatibility (will be deprecated in future).
  </action>
  <verify>
Run `go build ./...` - should compile without errors.
Check that models package exports AggregateProgress and FileProgress.
  </verify>
  <done>
AggregateProgress and FileProgress structs defined with JSON tags.
Both structs are importable from models package.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create ProgressAggregator with throttling and smoothing</name>
  <files>internal/sync/progress.go</files>
  <action>
Create new file `internal/sync/progress.go` with ProgressAggregator:

```go
package sync

import (
    "SyncDev/internal/models"
    "sync"
    "time"
)

const (
    // Throttle emissions to ~15 Hz (66ms)
    emitInterval = 66 * time.Millisecond
    // Exponential smoothing factor (0.1 = slow/stable)
    smoothingAlpha = 0.1
    // Max active files to include in emission
    maxActiveFiles = 10
    // Don't show ETA until this % complete
    minETAPercentage = 5.0
)

// ProgressAggregator collects per-file progress and emits throttled aggregates
type ProgressAggregator struct {
    mu sync.RWMutex

    // Per-file tracking
    files map[string]*fileState

    // Aggregate totals
    totalFiles       int
    completedFiles   int
    totalBytes       int64
    transferredBytes int64

    // Smoothed speed calculation
    smoothedSpeed    float64
    lastSpeedUpdate  time.Time
    lastTransferred  int64

    // Emission control
    callback    func(*models.AggregateProgress)
    lastEmit    time.Time
    status      string  // "idle", "syncing", "complete"

    // Lifecycle
    stopChan chan struct{}
    stopped  bool
}

type fileState struct {
    path        string
    size        int64
    transferred int64
    status      string // "active", "pending", "complete"
    startTime   time.Time
}

// NewProgressAggregator creates a new aggregator
func NewProgressAggregator(callback func(*models.AggregateProgress)) *ProgressAggregator {
    return &ProgressAggregator{
        files:    make(map[string]*fileState),
        callback: callback,
        status:   "idle",
        stopChan: make(chan struct{}),
    }
}

// StartSync initializes a new sync operation
func (pa *ProgressAggregator) StartSync(totalFiles int, totalBytes int64) {
    pa.mu.Lock()
    defer pa.mu.Unlock()

    pa.files = make(map[string]*fileState)
    pa.totalFiles = totalFiles
    pa.completedFiles = 0
    pa.totalBytes = totalBytes
    pa.transferredBytes = 0
    pa.smoothedSpeed = 0
    pa.lastSpeedUpdate = time.Now()
    pa.lastTransferred = 0
    pa.status = "syncing"

    pa.emitLocked(true) // Force emit on start
}

// UpdateFile updates progress for a specific file
func (pa *ProgressAggregator) UpdateFile(path string, size, transferred int64) {
    pa.mu.Lock()
    defer pa.mu.Unlock()

    fs, exists := pa.files[path]
    if !exists {
        fs = &fileState{
            path:      path,
            size:      size,
            status:    "active",
            startTime: time.Now(),
        }
        pa.files[path] = fs
    }

    // Update transferred delta
    delta := transferred - fs.transferred
    if delta > 0 {
        pa.transferredBytes += delta
    }
    fs.transferred = transferred
    fs.size = size // Size might not be known initially

    // Check if file completed
    if transferred >= size && size > 0 {
        fs.status = "complete"
        pa.completedFiles++
    }

    // Update smoothed speed
    pa.updateSpeed()

    // Maybe emit (throttled)
    pa.maybeEmit()
}

// CompleteFile marks a file as complete
func (pa *ProgressAggregator) CompleteFile(path string) {
    pa.mu.Lock()
    defer pa.mu.Unlock()

    if fs, exists := pa.files[path]; exists {
        if fs.status != "complete" {
            fs.status = "complete"
            pa.completedFiles++
        }
    }

    pa.maybeEmit()
}

// EndSync marks the sync operation as complete
func (pa *ProgressAggregator) EndSync() {
    pa.mu.Lock()
    defer pa.mu.Unlock()

    pa.status = "complete"
    pa.emitLocked(true) // Force final emit
}

// Reset clears all progress state
func (pa *ProgressAggregator) Reset() {
    pa.mu.Lock()
    defer pa.mu.Unlock()

    pa.files = make(map[string]*fileState)
    pa.totalFiles = 0
    pa.completedFiles = 0
    pa.totalBytes = 0
    pa.transferredBytes = 0
    pa.smoothedSpeed = 0
    pa.status = "idle"
}

// updateSpeed calculates smoothed speed using exponential moving average
func (pa *ProgressAggregator) updateSpeed() {
    now := time.Now()
    elapsed := now.Sub(pa.lastSpeedUpdate).Seconds()

    if elapsed < 0.1 { // Don't update more than 10x/sec
        return
    }

    bytesDelta := pa.transferredBytes - pa.lastTransferred
    instantSpeed := float64(bytesDelta) / elapsed

    if pa.smoothedSpeed == 0 {
        pa.smoothedSpeed = instantSpeed
    } else {
        pa.smoothedSpeed = smoothingAlpha*instantSpeed + (1-smoothingAlpha)*pa.smoothedSpeed
    }

    pa.lastSpeedUpdate = now
    pa.lastTransferred = pa.transferredBytes
}

// maybeEmit emits if enough time has passed since last emission
func (pa *ProgressAggregator) maybeEmit() {
    if time.Since(pa.lastEmit) >= emitInterval {
        pa.emitLocked(false)
    }
}

// emitLocked emits aggregate progress (must hold lock)
func (pa *ProgressAggregator) emitLocked(force bool) {
    if pa.callback == nil {
        return
    }

    if !force && time.Since(pa.lastEmit) < emitInterval {
        return
    }

    progress := pa.buildAggregate()
    pa.lastEmit = time.Now()

    // Release lock before callback to prevent deadlock
    pa.mu.Unlock()
    pa.callback(progress)
    pa.mu.Lock()
}

// buildAggregate constructs the AggregateProgress struct
func (pa *ProgressAggregator) buildAggregate() *models.AggregateProgress {
    var percentage float64
    if pa.totalBytes > 0 {
        percentage = float64(pa.transferredBytes) / float64(pa.totalBytes) * 100
    }

    // Calculate ETA
    eta := int64(-1)
    if pa.smoothedSpeed > 0 && percentage >= minETAPercentage {
        remaining := pa.totalBytes - pa.transferredBytes
        eta = int64(float64(remaining) / pa.smoothedSpeed)
    }

    // Collect active files (max 10)
    activeFiles := make([]models.FileProgress, 0, maxActiveFiles)
    for _, fs := range pa.files {
        if fs.status == "active" && len(activeFiles) < maxActiveFiles {
            var pct float64
            if fs.size > 0 {
                pct = float64(fs.transferred) / float64(fs.size) * 100
            }
            activeFiles = append(activeFiles, models.FileProgress{
                Path:        fs.path,
                Size:        fs.size,
                Transferred: fs.transferred,
                Percentage:  pct,
                Status:      fs.status,
            })
        }
    }

    return &models.AggregateProgress{
        Status:           pa.status,
        TotalFiles:       pa.totalFiles,
        CompletedFiles:   pa.completedFiles,
        TotalBytes:       pa.totalBytes,
        TransferredBytes: pa.transferredBytes,
        Percentage:       percentage,
        BytesPerSecond:   pa.smoothedSpeed,
        ETA:              eta,
        ActiveFiles:      activeFiles,
    }
}

// GetProgress returns current aggregate progress (thread-safe)
func (pa *ProgressAggregator) GetProgress() *models.AggregateProgress {
    pa.mu.RLock()
    defer pa.mu.RUnlock()
    return pa.buildAggregate()
}
```

Key design decisions:
- Throttle at 66ms (~15 Hz) to balance smoothness vs performance
- Exponential smoothing with alpha=0.1 for stable speed readings
- ETA only shown after 5% complete (insufficient data before)
- Max 10 active files in emission to avoid UI overload
- Thread-safe with proper mutex handling around callback
  </action>
  <verify>
Run `go build ./...` - should compile without errors.
Run `go test ./internal/sync/... -v` if tests exist (may be none yet).
Verify ProgressAggregator exports: NewProgressAggregator, StartSync, UpdateFile, CompleteFile, EndSync, GetProgress.
  </verify>
  <done>
ProgressAggregator implementation complete with:
- Throttled emissions at ~15 Hz
- Exponential smoothing for speed (alpha=0.1)
- ETA calculation with minimum threshold
- Thread-safe operations
- Max 10 active files tracking
  </done>
</task>

</tasks>

<verification>
After completing both tasks:
1. `go build ./...` compiles successfully
2. New files exist: `internal/models/progress.go`, `internal/sync/progress.go`
3. Grep for key exports: `grep -n "type AggregateProgress" internal/models/progress.go`
4. Grep for aggregator: `grep -n "type ProgressAggregator" internal/sync/progress.go`
</verification>

<success_criteria>
- AggregateProgress and FileProgress models defined with all required fields
- ProgressAggregator implements throttled emission (not every callback)
- Speed smoothing uses exponential moving average
- ETA calculation from smoothed speed
- Code compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-progress-display/03-01-SUMMARY.md`
</output>
